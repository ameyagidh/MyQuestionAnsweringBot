{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36a6898",
   "metadata": {},
   "source": [
    "## **Task:** Fine-tune a pre-trained Transformer-based chatbot using Tensorflow on the WikiQA corpus dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7368e6",
   "metadata": {},
   "source": [
    "### Approach:\n",
    "1. Exploratory Data Analysis.\n",
    "2. Data cleaning and preparation.\n",
    "3. Model training.\n",
    "4. Testing the model.\n",
    "5. Performing evaluations on Train and Test data.\n",
    "\n",
    "### The pipleline of the system is as follows:\n",
    "* **main.py:** The main file which performs all the tasks from exploratory data analysis, data-preparation, model-training, predictions, evaluations based on command line arguements given by user.\n",
    "* **Data_prep.py:** Contains the code and functions needed to clean all the train_data and transform the data which is ready to be feeded to the model.\n",
    "* **model.py:** This file contains the code to use the transformed data to fine-tune the bert model for a question answering task.\n",
    "* **Predictions.py:** This file contains all the code to perform predictions and evaluations on the testing data and example inputs given by user.\n",
    "* **utils.py:** This file contains all the helper_functions used in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f5f47e",
   "metadata": {},
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcacdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ameya Santosh Gidh\n",
    "\n",
    "This is the main file which performs tasks such as\n",
    "explorataroy data anaysis,data-preparation,model-training based on command line inputs.\n",
    "\"\"\"\n",
    "import sys\n",
    "from Exploratory_data_analysis import ExploratoryAnalysis\n",
    "from Data_prep import PrepareData\n",
    "from models import Models\n",
    "import pandas as pd\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from utils import load_model\n",
    "from Predictions import Predictions, Evaluations\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    \"\"\"\n",
    "        Main which takes command line arguements and executes the pipeline.\n",
    "\n",
    "        ARGS:\n",
    "            argv[1]: if given-1 performs exploratory data analysis on given data.\n",
    "            argv[2]: if given-1 performing preprocessing and prepares the final data.\n",
    "            argv[3]: if given-1 performs the training.\n",
    "            argv[4]: if given-1 performs predictions based on given inputs.\n",
    "            argv[5]: if given-1 performs evaluations and displays them.\n",
    "    \"\"\"\n",
    "    perform_eda = int(argv[1])\n",
    "    prepare_data = int(argv[2])\n",
    "    train_mode = int(argv[3])\n",
    "    prediction_mode = int(argv[4])\n",
    "    evaluation_mode = int(argv[5])\n",
    "\n",
    "    # Paths to data.\n",
    "    train_tsv_path = \"data/WikiQA-train.tsv\"\n",
    "    dev_tsv_path = \"data/WikiQA-dev.tsv\"\n",
    "    test_tsv_path = \"data/WikiQA-test.tsv\"\n",
    "\n",
    "    if perform_eda == 1:  # If given 1 by user perfrom EDA.\n",
    "        # Initialize the ExploratoryAnalysis object.\n",
    "        ob = ExploratoryAnalysis(train_tsv=train_tsv_path, dev_tsv=dev_tsv_path,\n",
    "                                 test_tsv=test_tsv_path)\n",
    "\n",
    "        ob.exploreTrainTsv()  # Performs EDA for TrainTSV.\n",
    "        ob.exploreDevTsv()  # Performs EDA for DevTSV.\n",
    "        ob.exploreTestTsv()  # Performs EDA for TestTSV\n",
    "\n",
    "    if prepare_data == 1:  # If given 1 by user prepares the data need to train the model.\n",
    "        pos_ans_path = \"data/WikiQASent.pos.ans.tsv\"\n",
    "        # Initialize the PrepareData object.\n",
    "        ob = PrepareData(train_tsv=train_tsv_path, dev_tsv=dev_tsv_path,\n",
    "                         test_tsv=test_tsv_path, pos_ans_tsv=pos_ans_path)\n",
    "        # Preprocess the data and prepares the final data that is ready for training.\n",
    "        ob.Preprocess()\n",
    "\n",
    "    # Note: Run prepare data atleast once before running for training data to be available.\n",
    "    if train_mode == 1:  # If given 1 by user the model training begins.\n",
    "        train_df = pd.read_csv(\"data/train.csv\")  # Load the train_df.\n",
    "        dev_df = pd.read_csv(\"data/dev.csv\")  # Load the dev_df.\n",
    "        test_df = pd.read_csv(\"data/test.csv\")  # Load the test_df\n",
    "        ob = Models(train_df, dev_df, test_df)\n",
    "        ob.train_model()  # Train the model.\n",
    "\n",
    "    # Note: Run train_model atleast once before you run this.\n",
    "    if prediction_mode == 1:  # If given 1 by user prediction mode turns on.\n",
    "        loaded_model = load_model(\"Models\")\n",
    "        # Load tokenizer from fine-tuned model.\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"Models\")\n",
    "        # Initialize the Predictions object.\n",
    "        ob = Predictions(loaded_model, tokenizer)\n",
    "        question = \"How will Diaphragm Pump work\"  # Input question\n",
    "        context = \"A diaphragm pump (also known as a Membrane pump, Air Operated Double Diaphragm Pump (AODD) or Pneumatic Diaphragm Pump) is a positive displacement pump that uses a combination of the reciprocating action of a rubber , thermoplastic or teflon diaphragm and suitable valves either side of the diaphragm ( check valve , butterfly valves, flap valves, or any other form of shut-off valves) to pump a fluid .\"\n",
    "        # Make a prediction using the loaded model and tokenizer\n",
    "        answer = ob.make_prediction(question, context)\n",
    "        print(\"Answer:\", answer)\n",
    "\n",
    "    # Note: Run train_model atleast once before you run this.\n",
    "    if evaluation_mode == 1:  # If given 1 by user computes and displays the metrics.\n",
    "        loaded_model = load_model(\"Models\")\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"Models\")\n",
    "        train_df = pd.read_csv(\"data/train.csv\")\n",
    "        dev_df = pd.read_csv(\"data/dev.csv\")\n",
    "        test_df = pd.read_csv(\"data/test.csv\")\n",
    "        eval_df = pd.read_csv(\"data/eval.csv\")\n",
    "        ob1 = Predictions(loaded_model, tokenizer)  # Predictions object.\n",
    "        # Evaluations object.\n",
    "        ob2 = Evaluations(train_df, dev_df, test_df, eval_df,\n",
    "                          loaded_model, tokenizer, ob1)\n",
    "        # Compute predictions and store them in a csv_file.\n",
    "        ob2.compute_store_predictions()\n",
    "        pr, re, f1 = ob2.display_metrics(pd.read_csv(\n",
    "            \"data/predictions.csv\"))\n",
    "        print(f\"train data:Precision is {pr} and recall is {re} and f1-score is {f1}\")\n",
    "        pr, re, f1 = ob2.display_metrics(pd.read_csv(\"data/eval_predictions.csv\"))\n",
    "        print(f\"test data:Precision is {pr} and recall is {re} and f1-score is {f1}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e73ea",
   "metadata": {},
   "source": [
    "### Order of Execution.\n",
    "1. Run the following command in command line python main.py \"arg1\" \"arg2\" \"arg3\" \"arg4\" \"arg5\"\n",
    "* **if arg-1=1** then the code base performs exploratary data analysis and displays the results.\n",
    "* **if arg-2=1** then the code base performs data cleaning and transforms it into form which is ready to be used to fine tune the Bert model for Question Answering task.\n",
    "* **if arg-3=1** then the code base trains the model by taking the transformed data.\n",
    "* **if arg-4=1** then the code base takes a input question and context given by user and returns the predicted results.\n",
    "* **if arg-5=1** then the code base computes the token-level precision, recall, f1-score for the entire training and evaluation datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3364336",
   "metadata": {},
   "source": [
    "### **Step-1:** Exploratory Data Analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e2e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_eda == 1:  # If given 1 by user perfrom EDA.\n",
    "        # Initialize the ExploratoryAnalysis object.\n",
    "        ob = ExploratoryAnalysis(train_tsv=train_tsv_path, dev_tsv=dev_tsv_path,\n",
    "                                 test_tsv=test_tsv_path)\n",
    "\n",
    "        ob.exploreTrainTsv()  # Performs EDA for TrainTSV.\n",
    "        ob.exploreDevTsv()  # Performs EDA for DevTSV.\n",
    "        ob.exploreTestTsv()  # Performs EDA for TestTSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9061a3",
   "metadata": {},
   "source": [
    "* **As shown in the above code snippet it first initialized the object of ExploratoryDataAnalysis class with paths of train, dev, test data sets and calls functions which displays the results for each of train, dev, test sets.**\n",
    "\n",
    "* **The ExloratoryAnalysis class in present in the Exploratory_data_analysis.py file given below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f931a",
   "metadata": {},
   "source": [
    "# Exploratory_data_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ameya Santosh Gidh\n",
    "\n",
    "This file contains code to perform exporatory data analysis.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ExploratoryAnalysis:\n",
    "    def __init__(self, train_tsv: str, dev_tsv: str, test_tsv: str):\n",
    "        \"\"\"\n",
    "        Initializes the train, dev, test paths with class variables.\n",
    "\n",
    "        ARGS:\n",
    "            train_tsv: Path to train_tsv file.\n",
    "            dev_tsv: Path to dev_tsv file.\n",
    "            test_tsv: Path to test_tsv file.\n",
    "        \"\"\"\n",
    "        self.train_tsv_path = train_tsv\n",
    "        self.dev_tsv_path = dev_tsv\n",
    "        self.test_tsv_path = test_tsv\n",
    "\n",
    "    def exploreData(self, data_path):\n",
    "        # Read and display the file as pandas dataFrame.\n",
    "        df = pd.read_csv(data_path, delimiter='\\t')\n",
    "        print(df.head(5))\n",
    "\n",
    "        # Get the number of data in the data.\n",
    "        print(f\"The number of data points in train_tsv file are {df.shape[0]}\")\n",
    "\n",
    "        # Check for the number of questions.\n",
    "        unique_questions = df['QuestionID'].unique()\n",
    "        print(f\"The number of unique questions are  {len(unique_questions)}\")\n",
    "\n",
    "        # check the count of no.of documents.\n",
    "        no_of_documents = df['DocumentID'].unique()\n",
    "        print(\n",
    "            f\"The number of documents in train_tsv file is {len(no_of_documents)}\")\n",
    "\n",
    "        # find the average no.of questions per document.\n",
    "        avg_questions_per_doc = df.groupby(\n",
    "            'DocumentID')['QuestionID'].nunique().mean()\n",
    "        # Print the result\n",
    "        print(\"Average number of unique QuestionID values per DocumentID:\",\n",
    "              avg_questions_per_doc)\n",
    "\n",
    "        # get list of documents with more than one question.\n",
    "        docs_with_multiple_questions = df.groupby('DocumentID').filter(\n",
    "            lambda x: x['QuestionID'].nunique() > 1)['DocumentID'].unique()\n",
    "        print(docs_with_multiple_questions)\n",
    "        print(\n",
    "            f\"No of documents with more than one question is {len(docs_with_multiple_questions)} which is {len(no_of_documents) / len(docs_with_multiple_questions)}%\")\n",
    "\n",
    "        # Find the average number of answers per question.\n",
    "        average_no_of_answers_per_question = df.groupby(\n",
    "            'QuestionID')['SentenceID'].nunique().mean()\n",
    "        print(\n",
    "            f\"Average no.of answers per question {average_no_of_answers_per_question}\")\n",
    "\n",
    "    def exploreTrainTsv(self):\n",
    "        print(f\"\\nExploratory DataAnalysis of train_tsv data\")\n",
    "        self.exploreData(self.train_tsv_path)\n",
    "\n",
    "    def exploreDevTsv(self):\n",
    "        print(f\"\\nExploratory DataAnalysis of dev_tsv data\")\n",
    "        self.exploreData(self.dev_tsv_path)\n",
    "\n",
    "    def exploreTestTsv(self):\n",
    "        print(f\"\\nExploratory DataAnalysis of test_tsv data\")\n",
    "        self.exploreData(self.test_tsv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa0597c",
   "metadata": {},
   "source": [
    "# **Step-2:** Data cleaning and preparation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d17f2",
   "metadata": {},
   "source": [
    "1. **Remove all the data points which have a sentence which do not contain correct answer.**\n",
    "2. **Get all unique questions in each of the data-split.**\n",
    "3. **Merge all the data-splits with all annotated answers from annotated dataset to create a final dataset with all the valid datapoints.**\n",
    "4. **Create the final valid dataset suitable for training by creating a dataframe with columns Question, Sentence, Answer**\n",
    "\n",
    "#### Key observations:\n",
    "* **There are a total of 1039 questions in the train_data with a proper answer.**\n",
    "* **There are a total of 140 questions in the train_data with a proper answer.**\n",
    "* **There are a total of 291 questions in the train_data with a proper answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb7a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prepare_data == 1:  # If given 1 by user prepares the data need to train the model.\n",
    "        pos_ans_path = \"data/WikiQASent.pos.ans.tsv\"\n",
    "        # Initialize the PrepareData object.\n",
    "        ob = PrepareData(train_tsv=train_tsv_path, dev_tsv=dev_tsv_path,\n",
    "                         test_tsv=test_tsv_path, pos_ans_tsv=pos_ans_path)\n",
    "        # Preprocess the data and prepares the final data that is ready for training.\n",
    "        ob.Preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0376b",
   "metadata": {},
   "source": [
    "**As shown above it takes the path to annotated datasets and Initializes the object of PrepareData class from Data_prep.py file, then calls Preprocess function which performs all the cleaning and transformations required for fine-tuning the model as shown below**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab304ca",
   "metadata": {},
   "source": [
    "# Data_prep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eedbbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "class PrepareData:\n",
    "    def __init__(self, train_tsv: str, dev_tsv: str, test_tsv: str, pos_ans_tsv: str):\n",
    "        \"\"\"\n",
    "        Creates the Necessary datframes required to create the final_data,\n",
    "        Initialize the object of this class with following args and then call \n",
    "        preprocess function to prepare your data.\n",
    "\n",
    "        ARGS:\n",
    "            train_tsv: Path to train_tsv file.\n",
    "            dev_tsv: Path to dev_tsv file.\n",
    "            test_tsv: Path to test_tsv file.\n",
    "        \"\"\"\n",
    "        self.train_tsv_path = train_tsv\n",
    "        self.dev_tsv_path = dev_tsv\n",
    "        self.test_tsv_path = test_tsv\n",
    "        self.pos_ans_tsv = pos_ans_tsv\n",
    "\n",
    "        # Initialize variables to store dataframes.\n",
    "        self.pos_ans_tsv_df = None\n",
    "        self.train_tsv_df = None\n",
    "        self.dev_tsv_df = None\n",
    "        self.test_tsv_df = None\n",
    "\n",
    "        # Initialize variables to store final train, dev, test dataframes.\n",
    "        self.final_train_df = None\n",
    "        self.final_dev_df = None\n",
    "        self.final_test_df = None\n",
    "\n",
    "    def create_data_frames(self):\n",
    "        # Creates the train, dev, test, pos_ans dataframes.\n",
    "        self.pos_ans_tsv_df = pd.read_csv(self.pos_ans_tsv, delimiter=\"\\t\")\n",
    "        self.train_tsv_df = pd.read_csv(self.train_tsv_path, delimiter=\"\\t\")\n",
    "        self.dev_tsv_df = pd.read_csv(self.dev_tsv_path, delimiter=\"\\t\")\n",
    "        self.test_tsv_df = pd.read_csv(self.test_tsv_path, delimiter=\"\\t\")\n",
    "\n",
    "    def create_final_df(self, df: pd.DataFrame):\n",
    "        # Takes in a dataframe and creates a new df ready for training\n",
    "        final_dict = {\n",
    "            'question': [],\n",
    "            'sentence': [],\n",
    "            'answer': []\n",
    "        }\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            # Iterate through each row and create new row for each of correct answer.\n",
    "            if pd.notna(row['AnswerPhrase1']) and row['AnswerPhrase1'] != 'NO_ANS':\n",
    "                final_dict['question'].append(row['Question'])\n",
    "                final_dict['sentence'].append(row['Sentence'])\n",
    "                final_dict['answer'].append(row['AnswerPhrase1'])\n",
    "\n",
    "            if pd.notna(row['AnswerPhrase2']) and row['AnswerPhrase2'] != 'NO_ANS':\n",
    "                final_dict['question'].append(row['Question'])\n",
    "                final_dict['sentence'].append(row['Sentence'])\n",
    "                final_dict['answer'].append(row['AnswerPhrase2'])\n",
    "\n",
    "            if pd.notna(row['AnswerPhrase3']) and row['AnswerPhrase3'] != 'NO_ANS':\n",
    "                final_dict['question'].append(row['Question'])\n",
    "                final_dict['sentence'].append(row['Sentence'])\n",
    "                final_dict['answer'].append(row['AnswerPhrase3'])\n",
    "\n",
    "        return pd.DataFrame(final_dict)\n",
    "\n",
    "    def Preprocess(self):\n",
    "        # Creates the final cleaned datasets and stored them in disk.\n",
    "        self.create_data_frames()  # Create dataframes.\n",
    "        # Preprocess the dataframes(eliminate all rows with incorrect sentences.)\n",
    "        cleaned_train_tsv_data = self.train_tsv_df[self.train_tsv_df[\"Label\"] == 1]\n",
    "        cleaned_dev_tsv_data = self.dev_tsv_df[self.dev_tsv_df[\"Label\"] == 1]\n",
    "        cleaned_test_tsv_data = self.test_tsv_df[self.test_tsv_df[\"Label\"] == 1]\n",
    "\n",
    "        # Get list of all unique_questions in the cleaned data.\n",
    "        unique_questions_train = cleaned_train_tsv_data['QuestionID'].unique()\n",
    "        unique_questions_dev = cleaned_dev_tsv_data['QuestionID'].unique()\n",
    "        unique_questions_test = cleaned_test_tsv_data['QuestionID'].unique()\n",
    "\n",
    "        # separate train_pos_ans_df for each of train, dev, test.\n",
    "        train_pos_ans_tsv = self.pos_ans_tsv_df[self.pos_ans_tsv_df['QuestionID'].isin(\n",
    "            unique_questions_train)]\n",
    "        dev_pos_ans_tsv = self.pos_ans_tsv_df[self.pos_ans_tsv_df['QuestionID'].isin(\n",
    "            unique_questions_dev)]\n",
    "        test_pos_ans_tsv = self.pos_ans_tsv_df[self.pos_ans_tsv_df['QuestionID'].isin(\n",
    "            unique_questions_test)]\n",
    "\n",
    "        # Merge train, dev, test dataframes with pos_ans dataframes.\n",
    "        merged_train_df = pd.merge(train_pos_ans_tsv, cleaned_train_tsv_data, on=[\n",
    "                                   \"QuestionID\", \"Question\", \"DocumentID\", \"DocumentTitle\", \"SentenceID\", \"Sentence\"])\n",
    "        merged_dev_df = pd.merge(dev_pos_ans_tsv, cleaned_dev_tsv_data, on=[\n",
    "                                 \"QuestionID\", \"Question\", \"DocumentID\", \"DocumentTitle\", \"SentenceID\", \"Sentence\"])\n",
    "        merged_test_df = pd.merge(test_pos_ans_tsv, cleaned_test_tsv_data, on=[\n",
    "                                  \"QuestionID\", \"Question\", \"DocumentID\", \"DocumentTitle\", \"SentenceID\", \"Sentence\"])\n",
    "\n",
    "        # Create the final dataframes.\n",
    "        self.final_train_df = self.create_final_df(merged_train_df)\n",
    "        self.final_dev_df = self.create_final_df(merged_dev_df)\n",
    "        self.final_test_df = self.create_final_df(merged_test_df)\n",
    "\n",
    "        # Save the final dataframes in a csv file.\n",
    "        self.final_train_df.to_csv(\"data/train.csv\", index=False)\n",
    "        self.final_dev_df.to_csv(\"data/dev.csv\", index=False)\n",
    "        self.final_test_df.to_csv(\"data/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaf1e97",
   "metadata": {},
   "source": [
    "**The final data-set contains a total of 1941 data points with Question,Sentence,Answer columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ecd5c",
   "metadata": {},
   "source": [
    "# Step-3:Model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788600e",
   "metadata": {},
   "source": [
    "**I have used Fine-tuned Bert to build the question-answering system.**\n",
    "1. First lets discuss about the Bert model which is basically a trained Transformer encoded stack.\n",
    "![example image](Bert_training.png \"Example Image\")\n",
    "2. As shown in the above picture Bert is first trained in a Semi-Supervised setting on large amount of data and then it can be used for various NLP tasks such as classification, Question-Answering etc.\n",
    "3. Bert has a total of two variants which are Bert-Base, Bert-Large where Bert-base has 12 attention heads and Bert-large has 16 attention heads with 768 and 1024 hidden units respectively.\n",
    "\n",
    "**Training Process for Bert**\n",
    "![example image](Bert-Model.png \"Example Image\")\n",
    "1. The First Input is always supplied with a special [CLS] token and each encoder layer will itself contain one Self-attention and its outputs are passed through a feed-forward network.\n",
    "2. One of the two important features of Bert are Masked Language Model(Randomly mask 15% of tokens) and Two-sentence Tasks (Given two sentences A and B is B likely to be sentence that follows A?)\n",
    "3. This is how we modify and Fine-Tune bert for Question-Answering task as shown in the Bert official paper.\n",
    "![example image](Bert-QA.png \"Example Image\")\n",
    "\n",
    "**Learning rate of 5 * 10 ^ -5 was choosed while fine-tuning for making model converge steadily and avoid overshooting the optimal solution.**\n",
    "\n",
    "**When it comes to loss function I have choosed Sparse-Categorical-Crossentropy this is because each position in the context can be considered a potential answer which makes it a multi-class problem with so many classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafac686",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Note: Run prepare data atleast once before running for training data to be available.\n",
    "    if train_mode == 1:  # If given 1 by user the model training begins.\n",
    "        train_df = pd.read_csv(\"data/train.csv\")  # Load the train_df.\n",
    "        dev_df = pd.read_csv(\"data/dev.csv\")  # Load the dev_df.\n",
    "        test_df = pd.read_csv(\"data/test.csv\")  # Load the test_df\n",
    "        ob = Models(train_df, dev_df, test_df)\n",
    "        ob.train_model()  # Train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e768e7a1",
   "metadata": {},
   "source": [
    "* As shown in the above code snippet it first initialized the object of Models class with paths of train, dev, test data sets and calls functions which trains the fine-tuned bert-base for 10 epochs.\n",
    "* The Model class in present in models.py file given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ameya Santosh Gidh\n",
    "\n",
    "This files contains the code to train and build models.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertModel\n",
    "from utils import preprocess_data\n",
    "from transformers import CONFIG_MAPPING\n",
    "\n",
    "\n",
    "class Models:\n",
    "    def __init__(self, train_data=None, dev_data=None, test_data=None):\n",
    "        \"\"\"\n",
    "        Takes the training_data, dev_data, test_data into one\n",
    "        final_data and trains the model.\n",
    "\n",
    "        Args:\n",
    "            train_data: training dataframe.\n",
    "            dev_data: dev_dataframe.\n",
    "            test_data: testing_dataframe.\n",
    "        \"\"\"\n",
    "        self.train_data = train_data\n",
    "        self.dev_data = dev_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "        # Combine the three data frames into a single dataframe.\n",
    "        self.final_data = pd.concat(\n",
    "            [self.train_data, self.dev_data, self.test_data], ignore_index=True)\n",
    "        self.sequence_length = 384\n",
    "        # Load pretrained tokenizer from bert model.\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Prepare the x_train and y_train splits to make it ready for training.\n",
    "        x_train, y_train = preprocess_data(questions=self.final_data['question'],\n",
    "                                           sentences=self.final_data['sentence'],\n",
    "                                           answers=self.final_data['answer'],\n",
    "                                           tokenizer=self.tokenizer,\n",
    "                                           seq_length=self.sequence_length)\n",
    "        return x_train, y_train\n",
    "\n",
    "    def create_qa_model(self):\n",
    "        # Finetunes the Bert model for question-answering task.\n",
    "        input_ids = tf.keras.layers.Input(\n",
    "            shape=(self.sequence_length, ), dtype=tf.int32, name='input_ids')\n",
    "        attention_mask = tf.keras.layers.Input(\n",
    "            shape=(self.sequence_length,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "        bert = TFBertModel.from_pretrained(\n",
    "            'bert-base-uncased', return_dict=True)\n",
    "        sequence_output = bert([input_ids, attention_mask])[\n",
    "            'last_hidden_state']\n",
    "\n",
    "        start_logits = tf.keras.layers.Dense(\n",
    "            1, name='start_position')(sequence_output)\n",
    "        # output layer to predict first_idx of answer.\n",
    "        start_logits = tf.keras.layers.Flatten()(start_logits)\n",
    "\n",
    "        end_logits = tf.keras.layers.Dense(\n",
    "            1, name='end_position')(sequence_output)\n",
    "        # output layer to predict last_idx of answer.\n",
    "        end_logits = tf.keras.layers.Flatten()(end_logits)\n",
    "\n",
    "        model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=[\n",
    "                               start_logits, end_logits])\n",
    "        return model\n",
    "\n",
    "    def train_model(self):\n",
    "        # trains the fine-tuned model for qa_task,\n",
    "        x_train, y_train = self.prepare_data()\n",
    "        qa_model = self.create_qa_model()\n",
    "\n",
    "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=5e-5)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        qa_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "        epochs = 10\n",
    "        batch_size = 8\n",
    "\n",
    "        history = qa_model.fit(x_train, [y_train['start_position'],\n",
    "                                         y_train['end_position']], epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "        model_save_path = \"Models\"\n",
    "\n",
    "        # Save the model weights\n",
    "        qa_model.save_weights(model_save_path + \"/tf_model.h5\")\n",
    "\n",
    "        # Save the tokenizer\n",
    "        self.tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "        # Save the config\n",
    "        config = CONFIG_MAPPING[\"bert\"]()\n",
    "        config.save_pretrained(model_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e0554",
   "metadata": {},
   "source": [
    "### Reasons for selecting Bert model and not selecting models such as GPT and T5\n",
    "1. **Bidirectional Context:** Bert is designed to capture context in both left and right sides of the token, thus this bidirectional context in bert allows it to better understand the contextual relation between words in a sentence. As explained in Bert paper GPT process the text in uni-directional way which limits its ability to understand context in text and more suitable for text generation tasks. Although T5 is bi-directional it is not as optimized as bert for bidirectional context representation.\n",
    "\n",
    "2. **Pre-training Objectives:** Masked Language Modelling and Next Sentence Prediction methods in Pre-training Bert makes Bert better understand language and context which is more useful for tasks like question answering while on contrast GPT uses a uni-directional modelling objective while T5 uses denoising autoencoder objective.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e2cf3",
   "metadata": {},
   "source": [
    "### Evaluation Metrics For Question Answering\n",
    "**How can we evaluate how better our model is performing with help of metrics such as Accuracy, Precision, Recall, F1-Score.**\n",
    "\n",
    "* As we are dealing with Question-Answering which is just as same as classification predicting the first and last index of the answer in sentence but as per the Bert paper they used a slightly modified version of these metrics to evaluate their model.\n",
    "* Accuracy -> We evaluate Accuracy as follows we compute accuracy for both the first_index and last_index predictions.\n",
    "* Precision -> It is caluculated as (Number of correct tokens in the predicted answer) / (Total number of tokens in the predicted answer).\n",
    "* Recall -> It is caluculated as (Number of correct tokens in the predicted answer) / (Total number of tokens in the actual answer).\n",
    "* F1-score -> 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "**In this way these metrics are computed for every data point in the dataset and then average values are reported as the overall performance of the model.**\n",
    "\n",
    "Let's understand this with an example.<br>\n",
    "Actual Answer: \"Paris\"<br>\n",
    "Predicted Answer: \"Paris city\"<br>\n",
    "\n",
    "Now let's calculate precision, recall, and F1-score for this example:<br>\n",
    "\n",
    "**Precision:**<br>\n",
    "Number of correct tokens in the predicted answer: 1 (\"Paris\")<br>\n",
    "Total number of tokens in the predicted answer: 2 (\"Paris\" and \"city\")<br>\n",
    "Precision = 1 (correct token) / 2 (total tokens in the predicted answer) = 0.5<br>\n",
    "\n",
    "**Recall:**<br>\n",
    "Number of correct tokens in the predicted answer: 1 (\"Paris\")<br>\n",
    "Total number of tokens in the actual answer: 1 (\"Paris\")<br>\n",
    "Recall = 1 (correct token) / 1 (total tokens in the actual answer) = 1<br>\n",
    "\n",
    "**F1-score:**<br>\n",
    "Precision = 0.5<br>\n",
    "Recall = 1<br>\n",
    "F1-score = 2 * (0.5 * 1) / (0.5 + 1) = 2 / 1.5 = 4 / 3 â‰ˆ 0.67<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8711261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if evaluation_mode == 1:  # If given 1 by user computes and displays the metrics.\n",
    "        loaded_model = load_model(\"Models\")\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"Models\")\n",
    "        train_df = pd.read_csv(\"data/train.csv\")\n",
    "        dev_df = pd.read_csv(\"data/dev.csv\")\n",
    "        test_df = pd.read_csv(\"data/test.csv\")\n",
    "        eval_df = pd.read_csv(\"data/eval.csv\")\n",
    "        ob1 = Predictions(loaded_model, tokenizer)  # Predictions object.\n",
    "        # Evaluations object.\n",
    "        ob2 = Evaluations(train_df, dev_df, test_df, eval_df,\n",
    "                          loaded_model, tokenizer, ob1)\n",
    "        # Compute predictions and store them in a csv_file.\n",
    "        ob2.compute_store_predictions()\n",
    "        pr, re, f1 = ob2.display_metrics(pd.read_csv(\n",
    "            \"data/predictions.csv\"))\n",
    "        print(f\"train data:Precision is {pr} and recall is {re} and f1-score is {f1}\")\n",
    "        pr, re, f1 = ob2.display_metrics(pd.read_csv(\"data/eval_predictions.csv\"))\n",
    "        print(f\"test data:Precision is {pr} and recall is {re} and f1-score is {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a223ee",
   "metadata": {},
   "source": [
    "**1.As shown in the above code snippet it first loads the fine-tuned model, tokenizer, training_data and Predictions, Evaluations classes object which are in predictions.py file and displays the metrics on training and testing data.**<br>\n",
    "\n",
    "**2.Then this calls relevant functions as shown above and displays the overall metrics**<br>\n",
    "\n",
    "**Accuracies on train data:** start_idx: 72.08%; end_idx: 84.56%<br>\n",
    "**Precision on train data:** 0.7901782329047791<br>\n",
    "**Recall on train data:** 0.8227536900992919<br>\n",
    "**F1-score on train data:** 0.7786718907778672<br>\n",
    "\n",
    "**Precision on test data:** 0.5045234018326576<br>\n",
    "**Recall on test data:** 0.5785156116685997 <br>\n",
    "**F1-score on test data:** 0.501535388012117 <br>\n",
    "\n",
    "**The Pipeline also facilitates to test the model with user input as given in the below snippet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52018f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Run train_model atleast once before you run this.\n",
    "    if prediction_mode == 1:  # If given 1 by user prediction mode turns on.\n",
    "        loaded_model = load_model(\"Models\")\n",
    "        # Load tokenizer from fine-tuned model.\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"Models\")\n",
    "        # Initialize the Predictions object.\n",
    "        ob = Predictions(loaded_model, tokenizer)\n",
    "        question = \"How will Diaphragm Pump work\"  # Input question\n",
    "        context = \"A diaphragm pump (also known as a Membrane pump, Air Operated Double Diaphragm Pump (AODD) or Pneumatic Diaphragm Pump) is a positive displacement pump that uses a combination of the reciprocating action of a rubber , thermoplastic or teflon diaphragm and suitable valves either side of the diaphragm ( check valve , butterfly valves, flap valves, or any other form of shut-off valves) to pump a fluid .\"\n",
    "        # Make a prediction using the loaded model and tokenizer\n",
    "        answer = ob.make_prediction(question, context)\n",
    "        print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f3582",
   "metadata": {},
   "source": [
    "# Predictions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e338f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Predictions:\n",
    "    def __init__(self, model: tf.Module, tokenizer: BertTokenizer):\n",
    "        \"\"\"\n",
    "        Initializes the class with model and tokenizer values.\n",
    "        model: The Pretrained model.\n",
    "        tokenizer: tokenizer with fine-tuned model weights.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def preprocess_input(self, question: str, context: str, tokenizer: BertTokenizer, sequence_length: int):\n",
    "        \"\"\"\n",
    "        Preprocesses the data and converts them into formats of input_ids, attention_masks, token_type_ids.\n",
    "\n",
    "        ARGS:\n",
    "            question: question which needs to be processed.\n",
    "            context: context that needs to be processed.\n",
    "            tokenizer: pretrained tokenizer with weights of pretrained model.\n",
    "            sequence_length: sequence_length of each word.\n",
    "\n",
    "        Returns:\n",
    "            returns a tuple of input_ids, attention_mask, token_type_ids.\n",
    "        \"\"\"\n",
    "\n",
    "        encoded_data = tokenizer.encode_plus(\n",
    "            question,\n",
    "            context,\n",
    "            add_special_tokens=True,\n",
    "            max_length=sequence_length,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors=\"tf\",\n",
    "        )\n",
    "\n",
    "        input_ids = encoded_data[\"input_ids\"]\n",
    "        attention_mask = encoded_data[\"attention_mask\"]\n",
    "        token_type_ids = encoded_data[\"token_type_ids\"]\n",
    "        return input_ids, attention_mask, token_type_ids\n",
    "\n",
    "    def get_answer(self, context: str, start_pos: int, end_pos: int, tokenizer: BertTokenizer):\n",
    "        \"\"\"\n",
    "        Extracts the final predicted answer based on start and end idx.\n",
    "\n",
    "        ARGS:\n",
    "            context: The context in which answer is present.\n",
    "            start_pos: Start index of the answer in context.\n",
    "            end_pos: end index of the answer in context.\n",
    "\n",
    "        Returns:\n",
    "            returns the final predicted answer.\n",
    "        \"\"\"\n",
    "        context_tokens = tokenizer.tokenize(context)\n",
    "        answer_tokens = context_tokens[start_pos:end_pos+1]\n",
    "        answer_text = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "\n",
    "        return answer_text\n",
    "\n",
    "    def make_prediction(self, question: str, context: str, sequence_length: int = 384):\n",
    "        \"\"\"\n",
    "        Displays the final answer by taking input question and context as parameter.\n",
    "\n",
    "        ARGS:\n",
    "            question: Input question.\n",
    "            context: Input context.\n",
    "            sequence_length: Max sequence to be taken for each word.\n",
    "\n",
    "        Returns:\n",
    "            returns the final answer if found.\n",
    "        \"\"\"\n",
    "        input_ids, attention_mask, token_type_ids = self.preprocess_input(\n",
    "            question, context, self.tokenizer, sequence_length)\n",
    "        start_logits, end_logits = self.model.predict(\n",
    "            [input_ids, attention_mask])\n",
    "\n",
    "        start_position = np.argmax(start_logits)\n",
    "        end_position = np.argmax(end_logits)\n",
    "\n",
    "        # Check if the end position is greater than or equal to the start position, otherwise return an empty string\n",
    "        if end_position >= start_position:\n",
    "            answer = self.get_answer(context, start_position,\n",
    "                                     end_position, self.tokenizer)\n",
    "        else:\n",
    "            answer = \"\"\n",
    "\n",
    "        return answer\n",
    "\n",
    "\n",
    "class Evaluations:\n",
    "    def __init__(self, train_df: pd.DataFrame, dev_df: pd.DataFrame, test_df: pd.DataFrame, eval_df: pd.DataFrame, model: tf.Module, tokens: BertTokenizer, pred_object: Predictions):\n",
    "        \"\"\"\n",
    "        Initializes the class with train, dev, test, fine-tuned\n",
    "        model, fine-tuned tokenizers and creates the final data required for \n",
    "        performing evaluations.\n",
    "\n",
    "        ARGS:\n",
    "            train_df: cleaned train data_frame.\n",
    "            dev_df: cleaned dev data_frame.\n",
    "            test_df: cleaned test data_frame.\n",
    "            model: fine-tuned model.\n",
    "            tokens: fine-tuned tokenizer.\n",
    "            pred_object: Predictions class object.\n",
    "        \"\"\"\n",
    "        self.train_df = train_df\n",
    "        self.dev_df = dev_df\n",
    "        self.test_df = test_df\n",
    "        self.eval_df = eval_df\n",
    "        self.model = model\n",
    "        self.tokenizer = tokens\n",
    "        self.final_data = pd.concat(\n",
    "            [self.train_df, self.dev_df, self.test_df], ignore_index=True)\n",
    "        self.pred_object = pred_object\n",
    "\n",
    "    def create_df(self, df: pd.DataFrame):\n",
    "        predict_dict = {\n",
    "            'actual_answer': [],\n",
    "            'predicted_answer': []\n",
    "        }\n",
    "        print(self.final_data.shape[0])\n",
    "        for i, row in tqdm(df.iterrows()):\n",
    "            question = row['question']\n",
    "            context = row['sentence']\n",
    "            actual_answer = row['answer']\n",
    "            predicted_answer = self.pred_object.make_prediction(\n",
    "                question, context)\n",
    "\n",
    "            predict_dict['actual_answer'].append(actual_answer)\n",
    "            predict_dict['predicted_answer'].append(predicted_answer)\n",
    "\n",
    "        df = pd.DataFrame(predict_dict)\n",
    "        return df\n",
    "\n",
    "    def compute_store_predictions(self):\n",
    "        # Computes the predicted answer for each question and stores them.\n",
    "        if not os.path.exists('data/predictions.csv'):\n",
    "            df = self.create_df(self.final_data)\n",
    "            df.to_csv(\"data/predictions.csv\", index=False)\n",
    "\n",
    "        if not os.path.exists('data/eval_predictions.csv'):\n",
    "            df1 = self.create_df(self.eval_df)\n",
    "            df1.to_csv(\"data/eval_predictions.csv\", index=False)\n",
    "\n",
    "    def precision_recall_f1(self, actual_answer: pd.Series, predicted_answer: pd.Series):\n",
    "        \"\"\"\n",
    "        Computes token level Precision, Recall, F1-score for the complete data.\n",
    "\n",
    "        ARGS:\n",
    "            actual_answer: A pandas series containing the actual answers.\n",
    "            predicted_answer: A pandas series containing the predicted answers.\n",
    "\n",
    "        Returns:\n",
    "            returns the token level Precision, Recall, F1. \n",
    "        \"\"\"\n",
    "        if type(actual_answer) == float or type(predicted_answer) == float:\n",
    "            return 0, 0, 0\n",
    "        actual_answer = actual_answer.lower()\n",
    "        predicted_answer = predicted_answer.lower()\n",
    "        actual_tokens = set(actual_answer.split())\n",
    "        predicted_tokens = set(predicted_answer.split())\n",
    "\n",
    "        # Find the common tokens between actual and predicted.\n",
    "        common_tokens = actual_tokens.intersection(predicted_tokens)\n",
    "\n",
    "        if len(predicted_tokens) == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = len(common_tokens) / len(predicted_tokens)\n",
    "\n",
    "        if len(actual_tokens) == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = len(common_tokens) / len(actual_tokens)\n",
    "\n",
    "        if precision + recall == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        return precision, recall, f1\n",
    "\n",
    "    def display_metrics(self, dataframe: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Takes in a dataframe of actual and predicted answers\n",
    "        and returns the overall token level precsion,\n",
    "        recall, f1-score.\n",
    "        \"\"\"\n",
    "        total_precision = 0\n",
    "        total_recall = 0\n",
    "        total_f1 = 0\n",
    "        num_examples = len(dataframe)\n",
    "\n",
    "        for index, row in dataframe.iterrows():\n",
    "            actual_answer = row['actual_answer']\n",
    "            predicted_answer = row['predicted_answer']\n",
    "            p, r, f1 = self.precision_recall_f1(\n",
    "                actual_answer, predicted_answer)\n",
    "\n",
    "            total_precision += p\n",
    "            total_recall += r\n",
    "            total_f1 += f1\n",
    "\n",
    "        overall_precision = total_precision / num_examples\n",
    "        overall_recall = total_recall / num_examples\n",
    "        overall_f1 = total_f1 / num_examples\n",
    "\n",
    "        return overall_precision, overall_recall, overall_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cbd5bb",
   "metadata": {},
   "source": [
    "# Utils.py\n",
    "**This file contains all the helper functions which were used in the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c76229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import BertConfig, BertTokenizer, TFBertModel\n",
    "\n",
    "\n",
    "def find_start_end_pos(sentence: str, answer: str, tokenizer: BertTokenizer):\n",
    "    \"\"\"\n",
    "    This function takes a sentence and answer as input and returns\n",
    "    the index of first_pos and last_pos of answer in the sentence.\n",
    "\n",
    "    Args:\n",
    "        sentence: A string variable containing sentence.\n",
    "        answer: A string variable containing answer.\n",
    "        tokenizer: BertTokenizer function.\n",
    "\n",
    "    Returns:\n",
    "        returns the start_idx and end_idx of answer in the sentence.\n",
    "    \"\"\"\n",
    "    sentence_tokens = tokenizer.tokenize(sentence)\n",
    "    answer_tokens = tokenizer.tokenize(answer)\n",
    "\n",
    "    # Initialize start and end_pos as -1.\n",
    "    start_idx = -1\n",
    "    end_idx = -1\n",
    "    for i, token in enumerate(sentence_tokens):\n",
    "        if token == answer_tokens[0] and sentence_tokens[i:i+len(answer_tokens)] == answer_tokens:\n",
    "            start_idx = i\n",
    "            end_idx = i + len(answer_tokens) - 1\n",
    "            break\n",
    "\n",
    "    return start_idx, end_idx\n",
    "\n",
    "\n",
    "def preprocess_data(questions: pd.Series, sentences: pd.Series, answers: pd.Series, tokenizer: BertTokenizer, seq_length: int):\n",
    "    \"\"\"\n",
    "    This function takes questions, sentences, answers and preprocess\n",
    "    them to make ready for training the model.\n",
    "\n",
    "    Args:\n",
    "        questions: An pd.series of questions from the data.\n",
    "\n",
    "    Returns:\n",
    "        returns the input_ids, attention_mask, start_position and end_position for\n",
    "        training the model.\n",
    "    \"\"\"\n",
    "    input_ids, attention_masks, start_positions, end_positions = [], [], [], []\n",
    "    for question, sentence, answer in zip(questions, sentences, answers):\n",
    "        # Encode the words.\n",
    "        encoder = tokenizer(question, sentence, padding='max_length',\n",
    "                            truncation=True, max_length=seq_length)\n",
    "        # Find the start and end_idx of answer.\n",
    "        start_pos, end_pos = find_start_end_pos(sentence, answer, tokenizer)\n",
    "\n",
    "        # Ignore rows where answer is not in the sentence.\n",
    "        if start_pos == -1 and end_pos == -1:\n",
    "            continue\n",
    "\n",
    "        input_ids.append(encoder['input_ids'])\n",
    "        attention_masks.append(encoder['attention_mask'])\n",
    "        start_positions.append(start_pos)\n",
    "        end_positions.append(end_pos)\n",
    "\n",
    "    return {\n",
    "        'input_ids': tf.constant(input_ids, dtype=tf.int32),\n",
    "        'attention_mask': tf.constant(attention_masks, dtype=tf.int32)\n",
    "    }, {\n",
    "        'start_position': tf.constant(start_positions, dtype=tf.int32),\n",
    "        'end_position': tf.constant(end_positions, dtype=tf.int32)\n",
    "    }\n",
    "\n",
    "# Load the model architecture\n",
    "\n",
    "\n",
    "def create_qa_model(config):\n",
    "    sequence_length = 384\n",
    "    input_ids = tf.keras.layers.Input(\n",
    "        shape=(sequence_length,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = tf.keras.layers.Input(\n",
    "        shape=(sequence_length,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "    bert = TFBertModel.from_pretrained('bert-base-uncased', config=config)\n",
    "    sequence_output = bert([input_ids, attention_mask])[0]\n",
    "\n",
    "    start_logits = tf.keras.layers.Dense(\n",
    "        1, name='start_position')(sequence_output)\n",
    "    start_logits = tf.keras.layers.Flatten()(start_logits)\n",
    "\n",
    "    end_logits = tf.keras.layers.Dense(1, name='end_position')(sequence_output)\n",
    "    end_logits = tf.keras.layers.Flatten()(end_logits)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=[\n",
    "                           start_logits, end_logits])\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model(model_path: str):\n",
    "    # Load the config.\n",
    "    config = BertConfig.from_pretrained(model_path)\n",
    "\n",
    "    # Load the model.\n",
    "    qa_model = create_qa_model(config)\n",
    "    qa_model.load_weights(model_path + \"/tf_model.h5\")\n",
    "    return qa_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7f4fd",
   "metadata": {},
   "source": [
    "## Challenges Faced.\n",
    "1. **One big challenge I faced was to tackle with the version Issues, Inorder to use M1-Mac gpu for training, Tensorflow 2.5 version must be used and original bert model was trained using a older version, to solve this problem I have used bert model from the transformers library of Hugging Face**\n",
    "2. **Another Issue I faced was as the dataset provided was more like a Open-Domain question answering which needs lots of data and number of valid datapoints were very less I had to combine the complete train, dev, testing data provided to train the model as WIKIQA was originally used for answer sentence selection.**\n",
    "3. **To get testing data for evaluation I have then used sites which are build on using state-of-the-art deep-learning models for paraphrasing**\n",
    "4. **Designing the Entire pipeline in an modularized way reducing in-efficiency and redundancy**.\n",
    "\n",
    "## Further Improvements.\n",
    "1. **Gather more data for training as Open-Domain question answering systems a lot of data as it needs to be more generalized.**\n",
    "2. **Try Fine-Tuning most recent state-of-the art Large-Language-Models such as GPT-3 and GPT-4.**\n",
    "3. **Try training the model by removing punctuations and other symbols.**\n",
    "4. **Research on designing more appropriate metric for evaluation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a29a44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
